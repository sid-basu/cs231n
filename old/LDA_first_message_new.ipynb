{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import airpy as ap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from gensim import corpora\n",
    "from gensim import models\n",
    "import pyLDAvis.gensim\n",
    "import csv\n",
    "import feather\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get common names list from disk\n",
    "path_names = '~/data/first_message_text_names.csv'\n",
    "common_names = list(pd.read_csv(path_names)['dim_first_name'])\n",
    "\n",
    "#get message text from disk\n",
    "path_messages = '~/data/first_message_text_lower.csv'\n",
    "df1 = pd.DataFrame(pd.read_csv(path_messages)['message_text_lower'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build documents list (remember to drop na's)\n",
    "documents = []\n",
    "for index, row in df1.iterrows():\n",
    "    documents.append(row.message_text_lower)\n",
    "    \n",
    "#generate a stoplist\n",
    "stoplist = stopwords.words('english')\n",
    "stoplist += common_names\n",
    "\n",
    "print 'common names done'\n",
    "\n",
    "# tokenize the text \n",
    "doc_token = [[word for word in list(gensim.utils.tokenize(document)) if word not in stoplist] for document in documents]\n",
    "\n",
    "print 'tokenization done'\n",
    "\n",
    "# build it into dictionary map\n",
    "dictionary = corpora.Dictionary(doc_token)\n",
    "\n",
    "# create the corpus for LDA \n",
    "corpus = [dictionary.doc2bow(message_text) for message_text in list(doc_token)]\n",
    "\n",
    "# convert to TD-IDF\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a LDA model\n",
    "%time \n",
    "\n",
    "lda_model_30 = gensim.models.LdaModel(corpus_tfidf, num_topics=30, alpha=0.0001, id2word=dictionary, passes=6)\n",
    "lda_model_30.save('lda_test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_30 = models.LdaModel.load('lda_test.model')\n",
    "cx_data =  pyLDAvis.gensim.prepare(lda_model_30, corpus_tfidf, dictionary)\n",
    "pyLDAvis.display(cx_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of message text, what topic was the most likely for that message text\n",
    "\n",
    "random.seed(20170710)\n",
    "#sample 10000 random contacts\n",
    "n_corpus = len(corpus)\n",
    "n_sample = 10000\n",
    "\n",
    "mask = random.sample(xrange(n_corpus), n_sample)\n",
    "messages_topics = []\n",
    "\n",
    "#find the most relevant topic to each of these documents\n",
    "for i in range(n_sample):\n",
    "    #get array of topics and probabilities for document i\n",
    "    results_i = lda_model_30[corpus[mask[i]]]\n",
    "    \n",
    "    ret = results_i[[item[1] for item in results_i].index(max([item[1] for item in results_i]))]\n",
    "    \n",
    "    messages_topics.append([documents[mask[i]], ret[0], ret[1]])\n",
    "    \n",
    "    \n",
    "messages_topic_0 = [x for x in messages_topics if x[1] == 0]\n",
    "messages_topic_1 = [x for x in messages_topics if x[1] == 1]\n",
    "messages_topic_2 = [x for x in messages_topics if x[1] == 2]\n",
    "messages_topic_3 = [x for x in messages_topics if x[1] == 3]\n",
    "messages_topic_4 = [x for x in messages_topics if x[1] == 4]\n",
    "messages_topic_5 = [x for x in messages_topics if x[1] == 5]\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
